{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "The dataset I will be working with contains information on various cars. For each car we have information about the technical aspects of the vehicle such as the motor's displacement, the weight of the car, the miles per gallon, and how fast the car accelerates. Using this information we will predict the origin of the vehicle, either North America, Europe, or Asia.\n",
    "\n",
    "Here are the columns in the dataset:\n",
    "\n",
    "- mpg -- Miles per gallon, Continuous.\n",
    "- cylinders -- Number of cylinders in the motor, Integer, Ordinal, and Categorical.\n",
    "- displacement -- Size of the motor, Continuous.\n",
    "- horsepower -- Horsepower produced, Continuous.\n",
    "- weight -- Weights of the car, Continuous.\n",
    "- acceleration -- Acceleration, Continuous.\n",
    "- year -- Year the car was built, Integer and Categorical.\n",
    "- origin -- Integer and Categorical. 1: North America, 2: Europe, 3: Asia.\n",
    "- car_name -- Name of the car.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cars = pd.read_csv(\"C:/Users/Jennifer/Documents/Python/Data/auto.csv\")\n",
    "cars.head()\n",
    "unique_regions = cars[\"origin\"].unique()\n",
    "print(unique_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  displacement horspower  weight  acceleration  origin  \\\n",
      "0  18.0         307.0       130    3504          12.0       1   \n",
      "1  15.0         350.0       165    3693          11.5       1   \n",
      "2  18.0         318.0       150    3436          11.0       1   \n",
      "3  16.0         304.0       150    3433          12.0       1   \n",
      "4  17.0         302.0       140    3449          10.5       1   \n",
      "\n",
      "                    car_name  cyl_3  cyl_4  cyl_5   ...     year_73  year_74  \\\n",
      "0  chevrolet chevelle malibu      0      0      0   ...           0        0   \n",
      "1          buick skylark 320      0      0      0   ...           0        0   \n",
      "2         plymouth satellite      0      0      0   ...           0        0   \n",
      "3              amc rebel sst      0      0      0   ...           0        0   \n",
      "4                ford torino      0      0      0   ...           0        0   \n",
      "\n",
      "   year_75  year_76  year_77  year_78  year_79  year_80  year_81  year_82  \n",
      "0        0        0        0        0        0        0        0        0  \n",
      "1        0        0        0        0        0        0        0        0  \n",
      "2        0        0        0        0        0        0        0        0  \n",
      "3        0        0        0        0        0        0        0        0  \n",
      "4        0        0        0        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy_cylinders = pd.get_dummies(cars[\"cylinders\"], prefix=\"cyl\")\n",
    "cars = pd.concat([cars, dummy_cylinders], axis=1)\n",
    "dummy_years = pd.get_dummies(cars[\"year\"], prefix=\"year\")\n",
    "cars = pd.concat([cars, dummy_years], axis=1)\n",
    "cars = cars.drop(\"year\", axis=1)\n",
    "cars = cars.drop(\"cylinders\", axis=1)\n",
    "print(cars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(cars.index)\n",
    "shuffled_cars = cars.iloc[shuffled_rows]\n",
    "highest_train_row = int(cars.shape[0] * .70)\n",
    "train = shuffled_cars.iloc[0:highest_train_row]\n",
    "test = shuffled_cars.iloc[highest_train_row:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MultiClass Regression Model\n",
    "n the one-vs-all approach, we're essentially converting an n-class (in our case n is 3) classification problem into n binary classification problems. For our case, we'll need to train 3 models:\n",
    "\n",
    "A model where all cars built in North America are considered Positive (1) and those built in Europe and Asia are considered Negative (0).\n",
    "A model where all cars built in Europe are considered Positive (1) and those built in North America and Asia are considered Negative (0).\n",
    "A model where all cars built in Asia are labeled Positive (1) and those built in North America and Europe are considered Negative (0).\n",
    "Each of these models is a binary classification model that will return a probability between 0 and 1. When we apply this model on new data, a probability value will be returned from each model (3 total). For each observation, we choose the label corresponding to the model that predicted the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "unique_origins = cars[\"origin\"].unique()\n",
    "unique_origins.sort()\n",
    "\n",
    "models = {}\n",
    "features = [c for c in train.columns if c.startswith(\"cyl\") or c.startswith(\"year\")]\n",
    "\n",
    "for origin in unique_origins:\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    X_train = train[features]\n",
    "    y_train = train[\"origin\"] == origin\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    models[origin] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_probs = pd.DataFrame(columns=unique_origins)\n",
    "testing_probs = pd.DataFrame(columns=unique_origins)  \n",
    "\n",
    "for origin in unique_origins:\n",
    "    # Select testing features.\n",
    "    X_test = test[features]   \n",
    "    # Compute probability of observation being in the origin.\n",
    "    testing_probs[origin] = models[origin].predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Origin\n",
    "Now that we trained the models and computed the probabilities in each origin we can classify each observation. To classify each observation we want to select the origin with the highest probability of classification for that observation.\n",
    "\n",
    "While each column in our dataframe testing_probs represents an origin we just need to choose the one with the largest probability. We can use the Dataframe method .idxmax() to return a Series where each value corresponds to the column or where the maximum value occurs for that observation. We need to make sure to set the axis paramater to 1 since we want to calculate the maximum value across columns. Since each column maps directly to an origin the resulting Series will be the classification from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      3\n",
      "4      2\n",
      "5      2\n",
      "6      1\n",
      "7      1\n",
      "8      1\n",
      "9      1\n",
      "10     2\n",
      "11     2\n",
      "12     3\n",
      "13     1\n",
      "14     1\n",
      "15     2\n",
      "16     1\n",
      "17     1\n",
      "18     1\n",
      "19     1\n",
      "20     2\n",
      "21     1\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     1\n",
      "26     3\n",
      "27     3\n",
      "28     1\n",
      "29     1\n",
      "      ..\n",
      "90     2\n",
      "91     1\n",
      "92     1\n",
      "93     1\n",
      "94     1\n",
      "95     1\n",
      "96     2\n",
      "97     3\n",
      "98     1\n",
      "99     1\n",
      "100    1\n",
      "101    1\n",
      "102    1\n",
      "103    2\n",
      "104    2\n",
      "105    1\n",
      "106    1\n",
      "107    1\n",
      "108    1\n",
      "109    2\n",
      "110    2\n",
      "111    3\n",
      "112    1\n",
      "113    2\n",
      "114    3\n",
      "115    3\n",
      "116    1\n",
      "117    2\n",
      "118    1\n",
      "119    1\n",
      "Length: 120, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predicted_origins = testing_probs.idxmax(axis=1)\n",
    "print(predicted_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
